{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "import itertools\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set random seem for reproducibility\n",
    "# manualSeed = 999\n",
    "# #manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "# print(\"Random Seed: \", manualSeed)\n",
    "# random.seed(manualSeed)\n",
    "# torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot='/clio/users/olgakr/DDSM/new_labels/3class/'\n",
    "dataroot2= '/clio/users/olgakr/DDSM/ddsm_patches/'\n",
    "\n",
    "dataroot3 = './ddsm_masks/train_masks/'  # mask path\n",
    "\n",
    "# Number of workers for dataloader\n",
    "num_workers = 12\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 1\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "# ngpu = 2 # sto alla3a parakatw. an 8es na alla3eis ton ari8mo twn GPU alla3e to\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\" poies GPU 8es\". aliws 8a mple3eis to GPU indexing\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "# device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# \"cuda\" oxi \"cuda:0\" -- me ton palio tropo ta estelnes stin 1h dia8esimi GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()  else \"cpu\")\n",
    "ngpu = torch.cuda.device_count()\n",
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load a Mask DataLoader based on the Augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## min kaneis def mesa stin init pote!\n",
    "class DDSM(torch.utils.data.Dataset):\n",
    "    def __init__(self, root1, root2, root3, split, transform):\n",
    "        self.root1 = root1\n",
    "        self.root2 = root2\n",
    "        self.root3 = root3\n",
    "\n",
    "        with open(os.path.join(root1, '{}.txt'.format(split)), 'r') as f:\n",
    "            for line in f:\n",
    "                if 'normal' in line:\n",
    "                    self.image_list = (list(map(self.process_line, f.readlines())))\n",
    "                    \n",
    "        self.mask_list = os.listdir(root3)\n",
    "            \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name, label = self.image_list[idx]\n",
    "        import pdb\n",
    "\n",
    "        image = Image.open(os.path.join(self.root2, image_name)).convert(\"L\")\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        mask_name = self.mask_list[idx]\n",
    "        mask = Image.open(os.path.join(self.root3,mask_name)) # edw de mporw na katalavw giati kaneis normalize!!!!!\n",
    "        mask = self.transform(mask) \n",
    "        \n",
    "        return image, label, mask    \n",
    "    \n",
    "    def process_line(self, line):\n",
    "        if 'normal' in line:\n",
    "            image_name, label = line.strip().split(' ')\n",
    "            label = int(label)\n",
    "            return image_name, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#                 transforms.Grayscale(num_output_channels=1),\n",
    "#                 transforms.Resize([64,64]),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "# ])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "#                 transforms.Grayscale(num_output_channels=1),\n",
    "                transforms.Resize([64,64]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5]) # edw de mporw na katalavw giati pernas kai ta mask!!!\n",
    "])\n",
    "\n",
    "train_dataset = DDSM(dataroot, dataroot2, dataroot3, 'train',  transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=18, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "### pote de ta stelnoume sti GPU!!!! to anti8eto!!!\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0][:10], padding=2, normalize=True),(1,2,0)))\n",
    "plt.show() ## an den kaneis show kanei accumulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_patch = real_batch[2]\n",
    "np.place(mask_patch.numpy(),mask_patch.numpy()>-1, [1])\n",
    "np.place(mask_patch.numpy(),mask_patch.numpy()==-1, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(mask_patch))\n",
    "print(torch.max(mask_patch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "# to idio!!!\n",
    "plt.imshow(np.transpose(vutils.make_grid(mask_patch[:16], padding=2, normalize=True),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function adds the mask as a noise input on the mammogram data (without modifying the original images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createpatch(mydata, masks, batch_size):\n",
    "    real = Variable(mydata.data.clone())\n",
    "    mask = Variable(masks.data.clone())\n",
    "    realdata = real[:batch_size]\n",
    "    maskdata = mask[:batch_size]\n",
    "    \n",
    "    ## find the mask location\n",
    "    maskpos = np.where(maskdata==1)\n",
    "    \n",
    "    #create index file\n",
    "    indices = np.empty((maskpos[0].shape[0], len(maskpos)))\n",
    "    for i in range(maskpos[0].shape[0]):\n",
    "    \n",
    "        indices[i] = np.array((maskpos[0][i],maskpos[1][i],maskpos[2][i], maskpos[3][i]))\n",
    "    \n",
    "    # transform real images to have a noise input\n",
    "    \n",
    "    for index in indices:\n",
    "        realdata[int(index[0])][int(index[1])][int(index[2])][int(index[3])] = np.random.uniform(-1,1)\n",
    "    \n",
    "    return realdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data & create a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olga = createpatch(real_batch[0], mask_patch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "## to idio!!\n",
    "# plt.imshow(np.transpose(vutils.make_grid(olga.to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.imshow(np.transpose(vutils.make_grid(olga[:10], padding=2, normalize=True),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(real_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(real_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Weight initialization for both Generator and Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Adversarial AutoEncoder Generatorv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "# exeis ta idia onomata sta def ton class kai sta montela\n",
    "# genika tis class me megalo to 1o gramma...\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "#         self.ngpu = ngpu ## de 3erw giati to exeis auto edw... sto svinw\n",
    "        #input 1x64x64\n",
    "        self.conv1 = nn.Conv2d(2, ngf, 3, 1, 1, bias=False) # one channel for the image one for the mask\n",
    "        self.bn1 = nn.BatchNorm2d(ngf)   \n",
    "        #first layer ngf x 64 x 64\n",
    "        self.conv2 = nn.Conv2d(ngf, ngf * 2, 4, 2, 1, bias=False)  # second layer will be concatenated (remember x and y)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf * 2)\n",
    "        #second layer ngf*2 x 32 x 32\n",
    "        self.conv3 = nn.Conv2d(ngf * 2, ngf * 4, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf * 4)\n",
    "        #third layer ngf*4 x 16 x 16\n",
    "        self.conv4 =  nn.Conv2d( ngf * 4, ngf * 8, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(ngf * 8)\n",
    "        #forth layer ngf*8 x 8 x 8\n",
    "        self.conv5 =  nn.Conv2d( ngf * 8, ngf * 16, 4, 2, 1, bias=False)\n",
    "        \n",
    "        #fifth layer ngf*16 x 4 x 4\n",
    "            \n",
    "    def forward(self, input, masking):\n",
    "        x = torch.cat([input, masking], 1)\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.2)\n",
    "        #print('1: ', x.shape)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)),0.2)\n",
    "        #print('2: ', x.shape)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)),0.2)\n",
    "        #print('3: ', x.shape)\n",
    "        x = F.leaky_relu(self.bn4(self.conv4(x)),0.2)\n",
    "        #print('4: ', x.shape)\n",
    "        x = torch.tanh(self.conv5(x))\n",
    "        #print('5: ', x.shape)\n",
    "        return x\n",
    "            \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "#         self.ngpu = ngpu ## de 3erw giati to exeis auto edw... sto svinw\n",
    "            \n",
    "        self.dec1 = nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(ngf*8)\n",
    "        #1st layer ngf* 8 x 8 x 8\n",
    "        self.dec2 = nn.ConvTranspose2d(ngf*8, ngf * 4, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf*4)\n",
    "        #2nd layer ngf*4 x 16 x 16\n",
    "        self.dec3 = nn.ConvTranspose2d(ngf*4, ngf * 2, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf*2)\n",
    "        #3rd ngf*2 x 32 x 32\n",
    "        self.dec4 = nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(ngf)\n",
    "        #4th layer ngf x 64 x 64\n",
    "        self.dec5 = nn.ConvTranspose2d(ngf, nc, 3, 1, 1, bias=False)\n",
    "        #5th layer 1 x 64 x 64\n",
    "     \n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.bn1(self.dec1(input)))\n",
    "        #print('1: ', x.shape)\n",
    "        x = F.relu(self.bn2(self.dec2(x)))\n",
    "        #print('2: ', x.shape)\n",
    "        x = F.relu(self.bn3(self.dec3(x)))\n",
    "        #print('3: ', x.shape)\n",
    "        x = F.relu(self.bn4(self.dec4(x)))\n",
    "        #print('4: ', x.shape)\n",
    "        x = torch.tanh(self.dec5(x))\n",
    "        #print('5: ', x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sou allazw ta 2 parakatw giati me auto ton tropo den epairnes kan ti swsti GPU!\n",
    "# Create the encoder\n",
    "encoder = Encoder()\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# prwta init kai meta se dataparallel\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "encoder.apply(weights_init)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and ngpu > 1:\n",
    "#     encoder = nn.DataParallel(encoder, list(range(ngpu))) ### ti einai auto pou kaneis edw de katalava..!\n",
    "    encoder = nn.DataParallel(encoder)\n",
    "\n",
    "\n",
    "\n",
    "# Print the model\n",
    "# print(encoder.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decoder\n",
    "decoder = Decoder()\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "# prwta init kai meta se dataparallel\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "decoder.apply(weights_init)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    decoder = nn.DataParallel(decoder)\n",
    "\n",
    "\n",
    "# Print the model\n",
    "print(decoder.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "#         self.ngpu = ngpu classika....\n",
    "        # min dineis onomata omws \"main\" !!!\n",
    "        self.mod = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64   \n",
    "            nn.Conv2d(nc, ndf , 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf ) x 32 x 32\n",
    "            nn.Conv2d(ndf , ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf * 2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf * 4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf * 8) x 4 x 4\n",
    "            nn.Conv2d(ndf *8 , 1, 4, 1, 0, bias=False),  \n",
    "            nn.Sigmoid()\n",
    "            # prob (0,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.mod(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator()\n",
    "netD = netD.to(device)\n",
    "\n",
    "# prwta init kai meta se dataparallel\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD) # ta idida...\n",
    "\n",
    "# Print the model\n",
    "print(netD.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de xreiazete na ta steileis ki auta... den sou trone polu xrono\n",
    "# adversarial_loss = torch.nn.BCELoss()\n",
    "# adversarial_loss = adversarial_loss.to(device)\n",
    "# pixelwise_loss = torch.nn.L1Loss()\n",
    "# pixelwise_loss = pixelwise_loss.to(device)\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "pixelwise_loss = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(itertools.chain(encoder.parameters(), decoder.parameters()), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish convention for real and fake labels during training\n",
    "fixed_noise = createpatch(real_batch[0], mask_patch, 64)\n",
    "fixed_noise = fixed_noise.to(device)\n",
    "\n",
    "\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "fake_labels = torch.zeros(batch_size, 1)\n",
    "\n",
    "\n",
    "label = torch.FloatTensor(batch_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, (data) in enumerate(train_loader,0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "    \n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0]\n",
    "        # leptomeries pou sou gemizoun tin 1h GPU\n",
    "        if ngpu < 2:\n",
    "            real_cpu.to(device)\n",
    "        mask = data[2]\n",
    "        \n",
    "        # ----------- >>>>>> ola auta steil'ta ston dataloader!!!!! edw xaneis para polu xrono\n",
    "        np.place(mask.numpy(),mask.numpy()>-1, [1])\n",
    "        np.place(mask.numpy(),mask.numpy()==-1, [0])\n",
    "        \n",
    "        #print('real:',real_cpu.shape)  # shape of the image tensor\n",
    "        b_size = real_cpu.size(0)\n",
    "        noise = createpatch(data[0], mask, b_size)\n",
    "        label = torch.full((b_size,), real_label)\n",
    "        # <<<<<<<<<<<----------- ||||||||||||||||||||||||||||||||||||||||||||\n",
    "        \n",
    "        # leptomeries pou sou gemizoun tin 1h GPU\n",
    "        if ngpu < 2:\n",
    "            noise = noise.to(device)\n",
    "            mask = mask.to(device)\n",
    "            label = label.to(device)\n",
    "       \n",
    "       \n",
    "        \n",
    "        \n",
    "        #print('label shape:', label.shape)  # shape of the real label tensor\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1) \n",
    "        #print(output)\n",
    "          \n",
    "        #print('output shape:', output.shape) # shape of the generated label tensor\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = adversarial_loss(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()  # the output of real images has to be close to 1 (prob for real close to 1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        \n",
    "        # Generate fake image batch with G\n",
    "        \n",
    "       \n",
    "        \n",
    "        encoded_imgs = encoder(noise.float(),mask.float())\n",
    "        fake = decoder(encoded_imgs)\n",
    "        \n",
    "        \n",
    "        #print('fake:',fake.shape)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        #print(label.shape)\n",
    "        #print(output.shape)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = adversarial_loss(output, label)  ### Label = 0 since it's fake, if D is good output should also be around 0\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()   # the output of fake images has to be close to 0 (prob for fake close to 0)\n",
    "        \n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = 0.5 * (errD_real + errD_fake)  ## a high score means a good discriminator (look on the DmaxGmin equation)\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        \n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = 0.001* (adversarial_loss(output, label)) + 0.999 * (pixelwise_loss(fake, real_cpu))\n",
    "        \n",
    "        # Calculate gradients for G\n",
    "        #reset_grad() do I need this?\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()  \n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch+1, num_epochs, i, len(train_loader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on generated images\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n",
    "            with torch.no_grad():\n",
    "                encoded_imgs = encoder(fixed_noise.float(), mask_patch.to(device).float())\n",
    "                fake = decoder(encoded_imgs)\n",
    "            img_list.append(vutils.make_grid(fake.detach().cpu(), padding=2, normalize=True))\n",
    "\n",
    "        iters += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
